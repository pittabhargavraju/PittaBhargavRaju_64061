# -*- coding: utf-8 -*-
"""Cats vs Dogs â€” Part 2: Pretrained CNN (VGG16) + Fine-tuning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YGWkDEwVQntsmSkeEifhGKf0Eek20b0B
"""

# Set Colab to GPU: Runtime > Change runtime type > GPU

import tensorflow as tf, os, random, shutil, zipfile, pathlib
print("TF:", tf.__version__)
print("GPU:", tf.config.list_physical_devices('GPU'))

# Upload your kaggle.json (Kaggle > Account > Create New API Token)
from google.colab import files
uploaded = files.upload()

os.makedirs("/root/.kaggle", exist_ok=True)
shutil.move("kaggle.json", "/root/.kaggle/kaggle.json")
os.chmod("/root/.kaggle/kaggle.json", 0o600)

!kaggle datasets download -d shaunthesheep/microsoft-catsvsdogs-dataset -p /content/data

zip_path = "/content/data/microsoft-catsvsdogs-dataset.zip"
with zipfile.ZipFile(zip_path, "r") as z:
    z.extractall("/content/data")

# Detect PetImages folder across common archive layouts
candidates = [
    "/content/data/PetImages",
    "/content/data/microsoft_cats_vs_dogs/PetImages",
    "/content/data/kagglecatsanddogs_3367a/PetImages",
]
pet_dir = None
for c in candidates:
    if os.path.isdir(c) and os.path.isdir(os.path.join(c, "Cat")) and os.path.isdir(os.path.join(c, "Dog")):
        pet_dir = c
        break

assert pet_dir, f"Could not find PetImages in {candidates}"
print("Dataset path:", pet_dir)

import os, pathlib, shutil, random
from PIL import Image

def is_ok_image(path: str) -> bool:
    """Quick verification that file opens and is not tiny."""
    try:
        with Image.open(path) as im:
            im.verify()
        with Image.open(path) as im:
            _ = im.getbands()
        return os.path.getsize(path) > 1024
    except Exception:
        return False

def list_images(dirpath: str):
    exts = ("*.jpg", "*.jpeg", "*.png", "*.JPG", "*.JPEG", "*.PNG")
    files = []
    p = pathlib.Path(dirpath)
    for pat in exts:
        files.extend([str(x) for x in p.glob(pat)])
    return sorted(files)

cats_raw = list_images(os.path.join(pet_dir, "Cat"))
dogs_raw = list_images(os.path.join(pet_dir, "Dog"))

# Filter corrupted or tiny files
cats_all = [p for p in cats_raw if is_ok_image(p)]
dogs_all = [p for p in dogs_raw if is_ok_image(p)]

print(f"After cleaning -> Cats: {len(cats_all)}  Dogs: {len(dogs_all)}")

random.seed(7)
random.shuffle(cats_all)
random.shuffle(dogs_all)

def _safe_encode_to_rgb(src_path: str, dest_path: str) -> bool:
    """Open with PIL, convert to RGB, save JPEG. Returns True if saved OK."""
    try:
        with Image.open(src_path) as im:
            im = im.convert("RGB")
            im.save(dest_path, format="JPEG", quality=95, optimize=True)
        return True
    except Exception:
        return False

def _copy_as_rgb(src_list, start, end, dest_dir, prefix):
    os.makedirs(dest_dir, exist_ok=True)
    saved, skipped = 0, 0
    for i, p in enumerate(src_list[start:end], start=1):
        fn = f"{prefix}_{i:06d}.jpg"
        ok = _safe_encode_to_rgb(p, os.path.join(dest_dir, fn))
        if ok:
            saved += 1
        else:
            skipped += 1
    return saved, skipped

def build_balanced_split(root_out, train_per_class, val_per_class=250, test_per_class=250,
                         cats_src=cats_all, dogs_src=dogs_all):
    """Create train/val/test folders, re-encoding every image to 3-channel RGB JPEG and skipping bad ones."""
    need = train_per_class + val_per_class + test_per_class
    if len(cats_src) < need or len(dogs_src) < need:
        raise ValueError("Not enough clean source images per class. Reduce counts or expand pools.")

    # Clean destination tree
    if os.path.exists(root_out):
        shutil.rmtree(root_out)
    for split in ["train", "val", "test"]:
        for cls in ["Cat", "Dog"]:
            os.makedirs(os.path.join(root_out, split, cls), exist_ok=True)

    # Take a small buffer in case a few images fail re-encode
    buffer = int(need * 0.15) + 50
    cats_pool = cats_src[:need + buffer]
    dogs_pool = dogs_src[:need + buffer]

    # Index ranges
    c_train_s, c_train_e = 0, train_per_class
    c_val_s,   c_val_e   = c_train_e, c_train_e + val_per_class
    c_test_s,  c_test_e  = c_val_e,   c_val_e + test_per_class

    d_train_s, d_train_e = 0, train_per_class
    d_val_s,   d_val_e   = d_train_e, d_train_e + val_per_class
    d_test_s,  d_test_e  = d_val_e,   d_val_e + test_per_class

    # Encode Cats
    a,b = _copy_as_rgb(cats_pool, c_train_s, c_train_e, os.path.join(root_out, "train", "Cat"), "cat_tr")
    c,d = _copy_as_rgb(cats_pool, c_val_s,   c_val_e,   os.path.join(root_out, "val",   "Cat"), "cat_va")
    e,f = _copy_as_rgb(cats_pool, c_test_s,  c_test_e,  os.path.join(root_out, "test",  "Cat"), "cat_te")

    # Encode Dogs
    g,h = _copy_as_rgb(dogs_pool, d_train_s, d_train_e, os.path.join(root_out, "train", "Dog"), "dog_tr")
    i,j = _copy_as_rgb(dogs_pool, d_val_s,   d_val_e,   os.path.join(root_out, "val",   "Dog"), "dog_va")
    k,l = _copy_as_rgb(dogs_pool, d_test_s,  d_test_e,  os.path.join(root_out, "test",  "Dog"), "dog_te")

    # Validate counts
    def count_imgs(p): return len(list(pathlib.Path(p).glob("*.jpg")))
    ct = count_imgs(os.path.join(root_out, "train", "Cat"))
    dt = count_imgs(os.path.join(root_out, "train", "Dog"))
    cv = count_imgs(os.path.join(root_out, "val",   "Cat"))
    dv = count_imgs(os.path.join(root_out, "val",   "Dog"))
    cte= count_imgs(os.path.join(root_out, "test",  "Cat"))
    dte= count_imgs(os.path.join(root_out, "test",  "Dog"))

    print(f"[Cats saved/skipped] train {a}/{b}, val {c}/{d}, test {e}/{f}")
    print(f"[Dogs saved/skipped] train {g}/{h}, val {i}/{j}, test {k}/{l}")
    print(f"[Final counts] train: Cat={ct}, Dog={dt} | val: Cat={cv}, Dog={dv} | test: Cat={cte}, Dog={dte}")

    assert ct == train_per_class and dt == train_per_class, "Did not meet train counts. Increase buffer or reduce size."
    assert cv == val_per_class   and dv == val_per_class,   "Did not meet val counts. Increase buffer or reduce size."
    assert cte == test_per_class and dte == test_per_class, "Did not meet test counts. Increase buffer or reduce size."

    return root_out

import tensorflow as tf, os

IMG_SIZE = (224, 224)   # good for VGG16 and general transfer
BATCH_SIZE = 32
AUTOTUNE = tf.data.AUTOTUNE

# Mild aug is usually enough for transfer
data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal"),
    tf.keras.layers.RandomRotation(0.05),
    tf.keras.layers.RandomZoom(0.1),
])

def make_datasets(root_out):
    train_ds = tf.keras.utils.image_dataset_from_directory(
        os.path.join(root_out, "train"),
        image_size=IMG_SIZE,
        batch_size=BATCH_SIZE,
        label_mode="binary",
        color_mode="rgb",
        shuffle=True,
    )
    val_ds = tf.keras.utils.image_dataset_from_directory(
        os.path.join(root_out, "val"),
        image_size=IMG_SIZE,
        batch_size=BATCH_SIZE,
        label_mode="binary",
        color_mode="rgb",
        shuffle=False,
    )
    test_ds = tf.keras.utils.image_dataset_from_directory(
        os.path.join(root_out, "test"),
        image_size=IMG_SIZE,
        batch_size=BATCH_SIZE,
        label_mode="binary",
        color_mode="rgb",
        shuffle=False,
    )

    def prep(ds, training=False):
        ds = ds.cache()
        if training:
            ds = ds.shuffle(2048)
        return ds.prefetch(AUTOTUNE)

    return prep(train_ds, True), prep(val_ds), prep(test_ds)

from tensorflow.keras import layers, models
from tensorflow.keras.applications import VGG16
from tensorflow.keras.applications.vgg16 import preprocess_input

def make_vgg_transfer_model(input_shape=IMG_SIZE+(3,), dropout=0.2, train_base=False, unfreeze_from=None):
    base = VGG16(include_top=False, weights="imagenet", input_shape=input_shape)

    # Freeze or selectively unfreeze
    if not train_base:
        base.trainable = False
    else:
        base.trainable = True
        if unfreeze_from is not None:
            set_trainable = False
            for layer in base.layers:
                if layer.name == unfreeze_from:
                    set_trainable = True
                layer.trainable = set_trainable

    inputs = layers.Input(shape=input_shape)
    x = data_augmentation(inputs)
    x = layers.Lambda(preprocess_input)(x)  # VGG16 preprocessing
    x = base(x, training=False)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dropout(dropout)(x)
    outputs = layers.Dense(1, activation="sigmoid")(x)

    model = models.Model(inputs, outputs)
    # LR: higher for transfer-only, lower for fine-tune
    model.compile(
        optimizer=tf.keras.optimizers.Adam(1e-4 if not train_base else 1e-5),
        loss="binary_crossentropy",
        metrics=["accuracy"],
    )
    return model

import matplotlib.pyplot as plt
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
import pandas as pd, os

def train_and_evaluate(model, train_ds, val_ds, test_ds, tag, epochs=15):
    os.makedirs("/content/checkpoints", exist_ok=True)
    ckpt = f"/content/checkpoints/{tag}_best.keras"
    callbacks = [
        EarlyStopping(patience=5, restore_best_weights=True, monitor="val_accuracy"),
        ReduceLROnPlateau(patience=2, factor=0.5, min_lr=1e-6, monitor="val_loss"),
        ModelCheckpoint(ckpt, save_best_only=True, monitor="val_accuracy"),
    ]
    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=callbacks, verbose=1)
    test_loss, test_acc = model.evaluate(test_ds, verbose=0)

    plt.figure()
    plt.plot(history.history["accuracy"], label="train_acc")
    plt.plot(history.history["val_accuracy"], label="val_acc")
    plt.xlabel("Epoch"); plt.ylabel("Accuracy"); plt.legend(); plt.title(f"Accuracy - {tag}")
    plt.show()

    plt.figure()
    plt.plot(history.history["loss"], label="train_loss")
    plt.plot(history.history["val_loss"], label="val_loss")
    plt.xlabel("Epoch"); plt.ylabel("Loss"); plt.legend(); plt.title(f"Loss - {tag}")
    plt.show()

    best_val = float(max(history.history["val_accuracy"]))
    return {"run": tag, "best_val_acc": best_val, "test_acc": float(test_acc)}

VAL_PER_CLASS = 250
TEST_PER_CLASS = 250
TRAIN_SIZES_PER_CLASS = [500, 2000, 4000]   # Step 1, Step 2, Step 3

RESULTS = []
ROOT = "/content/experiments_vgg"

for tpc in TRAIN_SIZES_PER_CLASS:
    exp_root = f"{ROOT}/train_per_class_{tpc}"
    build_balanced_split(exp_root, train_per_class=tpc,
                         val_per_class=VAL_PER_CLASS, test_per_class=TEST_PER_CLASS)
    train_ds, val_ds, test_ds = make_datasets(exp_root)

    # Transfer learning: freeze base, train top
    model_tl = make_vgg_transfer_model(train_base=False)
    summary_tl = train_and_evaluate(model_tl, train_ds, val_ds, test_ds,
                                    tag=f"vgg_transfer_tpc{tpc}", epochs=15)
    summary_tl["train_per_class"] = tpc
    summary_tl["total_train"] = tpc * 2
    summary_tl["phase"] = "transfer_only"
    RESULTS.append(summary_tl)

import pandas as pd
df_transfer = pd.DataFrame(RESULTS)
df_transfer = df_transfer[["run", "phase", "train_per_class", "total_train", "best_val_acc", "test_acc"]]
df_transfer.sort_values(["train_per_class", "phase"], inplace=True)
df_transfer.reset_index(drop=True, inplace=True)
df_transfer

# Fine-tune upper blocks for extra gains
# Unfreeze from "block4_conv1" (keeps early features stable)
for tpc in TRAIN_SIZES_PER_CLASS:
    exp_root = f"{ROOT}/train_per_class_{tpc}"
    train_ds, val_ds, test_ds = make_datasets(exp_root)

    model_ft = make_vgg_transfer_model(train_base=True, unfreeze_from="block4_conv1")
    summary_ft = train_and_evaluate(model_ft, train_ds, val_ds, test_ds,
                                    tag=f"vgg_finetune_tpc{tpc}", epochs=10)
    summary_ft["train_per_class"] = tpc
    summary_ft["total_train"] = tpc * 2
    summary_ft["phase"] = "fine_tune_from_block4"
    RESULTS.append(summary_ft)

df_all = pd.DataFrame(RESULTS)
df_all = df_all[["run", "phase", "train_per_class", "total_train", "best_val_acc", "test_acc"]]
df_all.sort_values(["train_per_class", "phase", "run"], inplace=True)
df_all.reset_index(drop=True, inplace=True)
df_all

csv_path = "/content/dogs_vs_cats_pretrained_results.csv"
df_all.to_csv(csv_path, index=False)
print("Saved:", csv_path)

print("\nTransfer-only summary:")
display(df_transfer)
print("\nAll runs (including fine-tune):")
display(df_all)

# optional for comparison

import matplotlib.pyplot as plt
import pandas as pd

df_all = pd.read_csv("/content/dogs_vs_cats_pretrained_results.csv")

plt.figure(figsize=(7,5))
for phase in df_all["phase"].unique():
    d = df_all[df_all["phase"] == phase]
    plt.plot(d["total_train"], d["test_acc"], marker="o", label=phase)
plt.xlabel("Total training images")
plt.ylabel("Test accuracy")
plt.title("Transfer learning vs fine-tuning performance")
plt.legend()
plt.grid(True)
plt.show()